{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Filters"
      ],
      "metadata": {
        "id": "rqESbHCJpzX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLuKyqT2n-LK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "from skimage.util import random_noise\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.color import gray2rgb\n",
        "import skimage.io\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/gdrive/MyDrive/lena256.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "EeRNtr2ZoB0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(gray_img, cmap=\"gray\")\n",
        "plt.title(\"Gray Scale\")"
      ],
      "metadata": {
        "id": "xwzJITQ9oBxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Mean_filter = cv2.blur(gauss,(5,5)) #kernel size 15 Avg\n",
        "Gauss_Filter = cv2.GaussianBlur(gauss, (15, 15), 0) #kernel size 15\n",
        "Median_Filter = cv2.medianBlur(np.float32(gauss), 5)\n",
        "BilateralFilter = cv2.bilateralFilter(np.float32(gauss),4,75,75)\n",
        "\n",
        "gauss_grey = rgb2gray(gauss)\n",
        "kernel = gaussian_kernel(3)\n",
        "filtered_img = wiener_filter(np.float32(gauss_grey), kernel, K = 30)"
      ],
      "metadata": {
        "id": "5oObV3dWoBvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,5, figsize=(15,15))\n",
        "\n",
        "ax[0].imshow(Mean_filter, cmap=\"gray\");\n",
        "ax[1].imshow(Gauss_Filter, cmap=\"gray\");\n",
        "ax[2].imshow(Median_Filter, cmap=\"gray\");\n",
        "ax[3].imshow(BilateralFilter, cmap=\"gray\");\n",
        "ax[4].imshow(filtered_img, cmap=\"gray\");\n",
        "\n",
        "\n",
        "ax[0].set_title('Mean Filter')\n",
        "ax[1].set_title('Gauss Filter')\n",
        "ax[2].set_title('Median Filter')\n",
        "ax[3].set_title('BilateralFilter Filter')\n",
        "ax[4].set_title('Weiner Filter')"
      ],
      "metadata": {
        "id": "rAy3xAlsoBso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Thresholding"
      ],
      "metadata": {
        "id": "FYoXnG_IoBqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret, otsu = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  ## do with grey scale image\n",
        "plt.imshow(otsu, cmap='gray')\n",
        "plt.title(\"Otsu thresholding\")"
      ],
      "metadata": {
        "id": "AXXkJyi3oBna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret, thresh1 = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)  ## do with grey scale image\n",
        "ret, thresh2 = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "ret, thresh3 = cv2.threshold(img, 120, 255, cv2.THRESH_TRUNC)\n",
        "ret, thresh4 = cv2.threshold(img, 120, 255, cv2.THRESH_TOZERO)\n",
        "ret, thresh5 = cv2.threshold(img, 120, 255, cv2.THRESH_TOZERO_INV)"
      ],
      "metadata": {
        "id": "dzue-zsKoBkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada_thresh1 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 199, 5) ## do with grey scale image\n",
        "ada_thresh2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 199, 5)"
      ],
      "metadata": {
        "id": "dbxeg9ddoBiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edge detection"
      ],
      "metadata": {
        "id": "t4bT-hnSoBfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sobelx = cv2.Sobel(image,cv2.CV_64F,1,0,ksize=1)# do with rgb image\n",
        "sobely = cv2.Sobel(image,cv2.CV_64F,0,1,ksize=1)\n",
        "sobelxy = cv2.Sobel(src=image, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=1) "
      ],
      "metadata": {
        "id": "ZX59leu5oBcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernelx = np.array([[50,50,50],[0,0,0],[-50,-50,-50]])\n",
        "kernely = np.array([[-50,0,50],[-50,0,50],[-50,0,50]])\n",
        "\n",
        "img_prewittx = cv2.filter2D(gauss, -1, kernelx)## do with gaussian blur image\n",
        "img_prewitty = cv2.filter2D(gauss, -1, kernely)"
      ],
      "metadata": {
        "id": "C9op4YzToBZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 15\n",
        "laplacian = cv2.Laplacian(gauss,cv2.CV_64F,ksize = kernel_size)## do with gaussian blur image"
      ],
      "metadata": {
        "id": "Y3O_C16roBXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.median(image)\n",
        "sigma=1.5\n",
        "#---- apply automatic Canny edge detection using the computed median----\n",
        "lower = int(max(0, (1.0 - sigma) * v))\n",
        "upper = int(min(255, (1.0 + sigma) * v))\n",
        "edged = cv2.Canny(image, lower, upper) ## do with RGB blur image"
      ],
      "metadata": {
        "id": "ondd8kSwoBUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fourier Transform ## use grayscale image/ "
      ],
      "metadata": {
        "id": "6zSYGNn6w-tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Numpy fourier\n",
        "f = np.fft.fft2(image) ## use grayscale image/ magnitude_spectrum\n",
        "fshift = np.fft.fftshift(f)\n",
        "magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
        "\n",
        "plt.figure(figsize=(17,17))\n",
        "plt.subplot(121), plt.imshow(image, cmap = 'gray')\n",
        "plt.title('Input Image'), plt.xticks([]), plt.yticks([]) \n",
        "plt.subplot(122), plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
        "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([]) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iUECSUIUw-p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Numpy inverse fourier\n",
        "\n",
        "rows, cols = image.shape ##input image/img_back\n",
        "crow,ccol = rows//2 , cols//2\n",
        "fshift[crow-30:crow+30, ccol-30:ccol+30] = 0\n",
        "f_ishift = np.fft.ifftshift(fshift)\n",
        "img_back = np.fft.ifft2(f_ishift)\n",
        "img_back = np.abs(img_back)"
      ],
      "metadata": {
        "id": "28lc4hMNw-nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## OpenCV fourier\n",
        "dft = cv2.dft(np.float32(image),flags = cv2.DFT_COMPLEX_OUTPUT) ## magnitude_spectrum\n",
        "dft_shift = np.fft.fftshift(dft)\n",
        "\n",
        "magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))"
      ],
      "metadata": {
        "id": "JokZ4EnAw-kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## OpenCV inverse fourier/ image_back\n",
        "rows, cols = image.shape\n",
        "crow,ccol = rows//2 , cols//2\n",
        "\n",
        "# create a mask first, center square is 1, remaining all zeros\n",
        "mask = np.zeros((rows,cols,2),np.uint8)\n",
        "mask[crow-30:crow+30, ccol-30:ccol+30] = 1\n",
        "\n",
        "# apply mask and inverse DFT\n",
        "fshift = dft_shift*mask\n",
        "f_ishift = np.fft.ifftshift(fshift)\n",
        "img_back = cv2.idft(f_ishift)\n",
        "img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])"
      ],
      "metadata": {
        "id": "K_UmP8iaw-hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RUTcBOm_w-Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "MMoJY9f7oBRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR = 'C:/Users/V Padmaja/Downloads/Brain_Tumor/Training/'\n",
        "CATEGORIES = ['glioma', 'Notumor']\n",
        "IMG_SIZE=100"
      ],
      "metadata": {
        "id": "AnQi3Vz8oBOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in CATEGORIES: ## visualizing\n",
        "    path=os.path.join(DATADIR, category)\n",
        "    for img in os.listdir(path):\n",
        "        img_array=cv2.imread(os.path.join(path,img))\n",
        "        plt.imshow(img_array)\n",
        "        plt.show()\n",
        "        break\n",
        "    break"
      ],
      "metadata": {
        "id": "_tKgJCrioBLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=[] ## preprocessing\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path=os.path.join(DATADIR, category)\n",
        "        class_num=CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array=cv2.imread(os.path.join(path,img))\n",
        "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
        "                training_data.append([new_array,class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "create_training_data() "
      ],
      "metadata": {
        "id": "3qRhgLV7oBIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for categories, label in training_data:\n",
        "    X.append(categories)\n",
        "    y.append(label)\n",
        "X= np.array(X).reshape(lenofimage,-1)\n",
        "X.shape\n",
        "X = X/255.0\n",
        "y=np.array(y)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "zn-NcDwRoBFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "metadata": {
        "id": "ERJVcbQloBCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel='linear',gamma='auto')\n",
        "svc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "psRv0idBoA-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = svc.predict(X_test)"
      ],
      "metadata": {
        "id": "vPEvdKy9oA0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy on data is\",accuracy_score(y_test,y2))"
      ],
      "metadata": {
        "id": "n_Lo6GnsvxM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Accuracy report\",classification_report(y_test,y2))"
      ],
      "metadata": {
        "id": "DwcwbdNSvxDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM Sequential model"
      ],
      "metadata": {
        "id": "pT3_NoYmwSwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,Dense,MaxPool2D,Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DqBj6Ud4wSs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"C:/Users/V Padmaja/Downloads/Facial_Expression/train\"\n",
        "test_dir = \"C:/Users/V Padmaja/Downloads/Facial_Expression/test\"\n",
        "train_datagen = ImageDataGenerator(rescale=(1/255.),shear_range = 0.2,zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "training_set = train_datagen.flow_from_directory(directory = train_dir,target_size=(64,64),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode = \"sparse\")\n",
        "test_datagen = ImageDataGenerator(rescale=(1/255.))\n",
        "test_set = test_datagen.flow_from_directory(directory = test_dir,target_size=(64,64),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode = \"sparse\")"
      ],
      "metadata": {
        "id": "uBNcCe8uwSqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3, strides = 2,input_shape=(64,64,3)))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
        "\n",
        "model.add(Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "\n",
        "#Output layer\n",
        "model.add(Dense(5,kernel_regularizer=l2(0.01),activation = \"linear\"))"
      ],
      "metadata": {
        "id": "3-uD_6GfwSoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = \"hinge\", metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "yOZFwWmTwSlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x = training_set, validation_data = test_set, epochs=20)"
      ],
      "metadata": {
        "id": "mi4RJPTNwSeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4GZ1BYvewSL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, RocCurveDisplay, accuracy_score"
      ],
      "metadata": {
        "id": "OIgQ_VP2yKvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classpaths = ['/content/drive/MyDrive/Brain_Tumor/Training/meningioma','/content/drive/MyDrive/Brain_Tumor/Training/notumor'] ## Reading\n",
        "data = []\n",
        "target = []\n",
        "d = {'meningioma':0, 'notumor':1,}\n",
        "\n",
        "for classpath in classpaths:\n",
        "  c = classpath.split('/')[-1]\n",
        "  imgnames = os.listdir(classpath)\n",
        "  for imgname in imgnames:\n",
        "    imgpath = os.path.join(classpath,imgname)\n",
        "    img = cv2.imread(imgpath)\n",
        "    img = cv2.resize(img,(100,100))\n",
        "    img = np.array(img)\n",
        "    data.append(img)\n",
        "    target.append(d[c])"
      ],
      "metadata": {
        "id": "QfnshqnIyKrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = [0 for i in range(len(data))]\n",
        "for i,d in enumerate(data):\n",
        "  data2[i] = np.ravel(d)\n",
        "data = np.array(data2)\n",
        "target = np.array(target)\n",
        "\n",
        "traindata, testdata, traintarget, testtarget = train_test_split(data,target,test_size=0.2)\n",
        "\n",
        "print(traindata.shape)\n",
        "print(traintarget.shape)\n",
        "print(testdata.shape)\n",
        "print(testtarget.shape)"
      ],
      "metadata": {
        "id": "2ummN26_yKos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(traindata, traintarget)\n",
        "pred = lr.predict(testdata)\n",
        "print(\"Logistic Regression results: \")\n",
        "print(\"Accuracy score: \",accuracy_score(testtarget,pred))\n",
        "\n",
        "print(\"Confusion matrix: \")\n",
        "print(confusion_matrix(testtarget,pred))\n",
        "\n",
        "print(\"ROC curve: \")\n",
        "RocCurveDisplay.from_estimator(lr,testdata,testtarget)"
      ],
      "metadata": {
        "id": "hvso5SdWyKmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "knn = KNeighborsClassifier()\n",
        "rfc = RandomForestClassifier()\n"
      ],
      "metadata": {
        "id": "-8coD-HlyKjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "ZA4LqFDEyKgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import sys"
      ],
      "metadata": {
        "id": "Z8BRAesEyKde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(Dense(units=256, activation='relu'))\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(Dense(units=4, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "WwCQQWTnyKW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xeprHoJ-3-NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "evaluate_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "fJQOr0Tt3-Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/Brain_Tumor/Training', target_size=(32, 32), batch_size=64, class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory('/content/drive/MyDrive/Brain_Tumor/Testing', target_size=(32, 32), batch_size=64, class_mode='categorical')"
      ],
      "metadata": {
        "id": "0bq4pN0C3-HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_fit = classifier.fit_generator(train_generator, steps_per_epoch=25,epochs=25, validation_data=test_generator, validation_steps=10)"
      ],
      "metadata": {
        "id": "KCMBR7sq3-Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Train generator indices : \", train_generator.class_indices)\n",
        "score = classifier.evaluate_generator(test_generator, 32)"
      ],
      "metadata": {
        "id": "hbvE5HvS3-CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = score_fit.history['accuracy']\n",
        "val_acc = score_fit.history['val_accuracy']\n",
        "loss = score_fit.history['loss']\n",
        "val_loss = score_fit.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U2y4jFIW4NHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "soEIe0sn4NDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H9t2NmWw4NA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rnvjoHBf4M-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}